<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="AI-powered tool for solo improvisation training with dynamic story generation and creative prompts">
    <meta name="keywords" content="improvisation, acting, AI, training, multimodal, LLM">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ImprovMate: Multimodal AI Assistant for Improv Actor Training</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);    
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">ImprovMate: Multimodal AI Assistant for Improv Actor
                            Training</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://orcid.org/0009-0009-3628-044X" target="_blank">Riccardo
                                    Drago</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://orcid.org/0009-0002-5286-0080" target="_blank">Yotam
                                    Sechayk</a><sup>2</sup>,</span>
                            <span class="author-block">
                                <a href="https://orcid.org/0000-0003-3983-1955" target="_blank">Mustafa Doga
                                    Dogan</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://orcid.org/0000-0001-7916-1699" target="_blank">Andrea
                                    Sanna</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://orcid.org/0000-0002-5495-6441" target="_blank">Takeo
                                    Igarashi</a><sup>2</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <sup>1</sup>Department of Computer Engineering, Politecnico di Torino, Turin, Italy<br>
                                <sup>2</sup>Department of Creative Informatics, The University of Tokyo, Tokyo,
                                Japan<br>
                                <sup>3</sup>Adobe Research, Basel, Switzerland</span>
                            <br /><br />
                            <span class="author-block"><a href="https://doi.org/10.1145/3715668.3736363"
                                    target="_blank">DIS Work-in-Progress 2025</a></span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://doi.org/10.1145/3715668.3736363" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/tomfluff/ImprovMate/" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Demo Link. -->
                                <span class="link-block">
                                    <a href="https://tomfluff.github.io/ImprovMate/" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-laptop-code"></i>
                                        </span>
                                        <span>Demo</span>
                                    </a>
                                </span>

                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
                <p>Improvisation training for actors presents unique challenges, particularly in maintaining narrative
                    coherence and managing cognitive load during performances. Previous research on AI in improvisation
                    performance often predates advances in large language models (LLMs) and relies on human
                    intervention. We introduce <span class="dnerf">ImprovMate</span>, which leverages LLMs as <span
                        class="italic">GPTs</span> to automate the generation of
                    narrative stimuli and cues, allowing actors to focus on creativity without keeping track of plot or
                    character continuity. Based on insights from professional improvisers, <span
                        class="dnerf">ImprovMate</span> incorporates
                    exercises that mimic live training, such as abrupt story resolution and reactive thinking exercises,
                    while maintaining coherence via reference tables. By balancing randomness and structured guidance,
                    <span class="dnerf">ImprovMate</span> provides a groundbreaking tool for improv training. Our pilot
                    study revealed that actors
                    might embrace AI techniques if the latter mirrors traditional practices, and appreciate the fresh
                    twist introduced by our approach with the AI-generated cues.
                </p>
            </div>
        </div>
    </div>
    <!--/ Abstract. -->


    <section class="section">
        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Video</h2>
                <video id="teaser" autoplay loop playsinline controls height="300px">
                    <source src="./static/videos/ImprovMate_with_Captions.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <!--/ Paper video. -->

    </section>



    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content">
                            <h2 class="title is-3">Key Features of <span class="dnerf">ImprovMate</span> </h2>
                            <img src="./static/images/figure1.png" class="interpolation-image" width="100%" />
                        </div>
                        <h3 class="title is-4">Solo Improv Training Powered by AI</h3>
                        <p> <span class="dnerf">ImprovMate</span> enables actors to rehearse improvisation scenes
                            without the need for a human
                            partner. Using LLMs, the system generates story prompts, characters,
                            and narrative twists based on the actor's performance. It supports speech and motion input
                            via webcam and microphone, requiring no additional equipment. This makes solo practice
                            sessions both accessible and stimulating, closely mimicking live group training.
                        </p>
                        <h3 class="title is-4">Smart Narrative Support with Creative Hints</h3>
                        <div class="columns has-text-centered is-vcentered">
                            <div class="column is-half">
                                <img src="./static/images/hints.png" style="max-height: 450px; width: auto;" />
                            </div>
                            <div class="column is-half">
                                <img src="./static/images/keypoints.png" style="max-height: 450px; width: auto;" />
                            </div>
                        </div>
                        <p>To maintain flow and coherence during performances, <span class="dnerf">ImprovMate</span>
                            tracks key elements such as
                            characters, locations, and objects. The system also provides dynamic hints, as
                            unexpected
                            objects or character shifts, to inspire new directions in the story. These AI-generated
                            suggestions act like live audience prompts, helping performers remain spontaneous while
                            preserving consistency. The result is a balance between creative freedom and structured
                            storytelling.
                        </p>
                        <h3 class="title is-4">Realistic, Actor-Tested Improv Exercises</h3>
                        <p> <img style="float: left;padding-right: 30px;"
                                src="./static/images/improv_3_things_upscaled.png" width="450px" />
                            <br /><br /><br /><br />
                        <p> <span class="dnerf">ImprovMate</span> includes built-in exercises designed to improve
                            responsiveness and narrative
                            control. For example, <span class="italic">Three Things</span> trains fast thinking with
                            quirky prompts, while
                            <span class="italic">Endings</span> challenges users to wrap up complex stories in a single
                            take. These exercises are
                            based on real actor feedback and replicate activities used in improv groups. They are
                            especially useful for low-energy sessions, giving performers the chance to refine their
                            skills with minimal cognitive load.
                        </p><br />
                    </div>
                </div>
            </div>
        </div>
        </div>
        </div>
    </section>

    <!--
<section class="section">
  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Implementation</h2>

        <div class="content has-text-justified">
          
          <p>
            XR-Objects  leverages developments in spatial understanding via tools such as  SLAM, 
            available in <a
            href="https://developers.google.com/ar">Google ARCore </a> and 
            <a href="https://developer.apple.com/augmented-reality/arkit">Apple ARKit</a>, 
            and machine learning models for object segmentation and classification (<a href="https://cocodataset.org/COCO">COCO</a> 
            via <a href="https://developers.google.com/mediapipe">MediaPipe</a>), that enable us to implement AR interactions 
            with semantic depth.
            We also integrate a Multimodal Large Language Model (MLLM), 
            <a href="https://deepmind.google/technologies/gemini/">Google Gemini</a>, into our system, 
            which further enhances our ability to automate the recognition of objects and their specific 
            semantic information within XR spaces.  
          </p>
        
          <img poster="" id="fullbody" src="./static/images/pipeline_new.png">
        </div>
      </div>
    </div>
  </div>
</section>
	
-->

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@inproceedings{drago2025improvmate,
  author       = {Riccardo Drago and Yotam Sechayk and Mustafa Doga Dogan and Andrea Sanna and Takeo Igarashi},
  title        = {{ImprovMate: Multimodal AI Assistant for Improv Actor Training}},
  booktitle    = {Companion Publication of the 2025 ACM Designing Interactive Systems Conference (DIS ’25 Companion)},
  year         = {2025},
  publisher    = {Association for Computing Machinery},
  address      = {New York, NY, USA},
  doi          = {10.1145/3715668.3736363},
  isbn         = {979-8-4007-1486-3},
  url          = {https://doi.org/10.1145/3715668.3736363}
}
</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is built on top of the <a
                                href="https://github.com/nerfies/nerfies.github.io">Nerfies template</a>, <a
                                rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0</a> International License.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>